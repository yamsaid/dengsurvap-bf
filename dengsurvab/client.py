"""
Client principal pour l'API Appi Dengue

Ce module contient la classe AppiClient qui fournit une interface
compl√®te pour interagir avec l'API de surveillance de la dengue.
"""

import os
import requests
import pandas as pd
from typing import List, Optional, Dict, Any, Union
from datetime import datetime, date, timedelta
import json
import logging
from urllib.parse import urljoin

from .models import (
    CasDengue, SoumissionDonnee, AlertLog, SeuilAlert, User,
    ValidationCasDengue, IndicateurHebdo, Statistiques,
    LoginRequest, RegisterRequest, AlertConfigRequest
)
from .exceptions import (
    AppiException, AuthenticationError, APIError, ValidationError,
    RateLimitError, ConnectionError, create_exception_from_response
)
from .auth import AuthManager
from .alerts import AlertManager
from .export import DataExporter
from .analytics import EpidemiologicalAnalyzer

os.environ['APPI_API_URL'] = "https://api-bf-dengue-survey-production.up.railway.app/"

class AppiClient:
    """
    Client principal pour l'API de surveillance de la dengue Appi.
    
    Cette classe fournit une interface compl√®te pour acc√©der aux donn√©es
    √©pid√©miologiques, g√©rer les alertes et effectuer des analyses.
    """
    
    def __init__(self, 
                 
                 base_url: str = "https://api-bf-dengue-survey-production.up.railway.app/"
, 
                 api_key: Optional[str] = None,
                 timeout: int = 30,
                 retry_attempts: int = 3,
                 retry_delay: float = 1.0,
                 debug: bool = False):
        """
        Initialise le client Appi.
        
        Args:
            base_url: URL de base de l'API
            api_key: Cl√© API optionnelle
            timeout: Timeout des requ√™tes en secondes
            retry_attempts: Nombre de tentatives en cas d'√©chec
            retry_delay: D√©lai entre les tentatives en secondes
            debug: Mode debug pour les logs d√©taill√©s
        """
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.timeout = timeout
        self.retry_attempts = retry_attempts
        self.retry_delay = retry_delay
        self.debug = debug
        
        # Configuration du logging
        if debug:
            logging.basicConfig(level=logging.DEBUG)
        self.logger = logging.getLogger(__name__)
        
        # Session HTTP avec configuration
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'dengsurvap-bf/0.1.0',
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        })
        
        if api_key:
            self.session.headers.update({'Authorization': f'Bearer {api_key}'})
        
        # Modules sp√©cialis√©s
        self.auth = AuthManager(self)
        self.alerts = AlertManager(self)
        self.exporter = DataExporter(self)
        self.analyzer = EpidemiologicalAnalyzer(self)
        
        # Cache pour les requ√™tes fr√©quentes
        self._cache = {}
        self._cache_ttl = 300  # 5 minutes
        
    @classmethod
    def from_env(cls) -> 'AppiClient':
        """
        Cr√©e une instance du client √† partir des variables d'environnement.
        
        Returns:
            Instance du client configur√©e
            
        Raises:
            ConfigurationError: Si les variables requises sont manquantes
        """
        base_url = os.getenv('APPI_API_URL')
        api_key = os.getenv('APPI_API_KEY')
        debug = os.getenv('APPI_DEBUG', 'false').lower() == 'true'
        
        if not base_url:
            raise AppiException("Variable d'environnement APPI_API_URL requise")
        
        return cls(
            base_url=base_url,
            api_key=api_key,
            debug=debug
        )
    
    def _make_request(self, 
                     method: str, 
                     endpoint: str, 
                     params: Optional[Dict[str, Any]] = None,
                     data: Optional[Dict[str, Any]] = None,
                     files: Optional[Dict[str, Any]] = None,
                     headers: Optional[Dict[str, str]] = None,
                     use_form_data: bool = False) -> Dict[str, Any]:
        """
        Effectue une requ√™te HTTP vers l'API avec gestion d'erreurs et retry.
        
        Args:
            method: M√©thode HTTP (GET, POST, etc.)
            endpoint: Endpoint de l'API
            params: Param√®tres de requ√™te
            data: Donn√©es √† envoyer
            files: Fichiers √† envoyer
            headers: Headers HTTP suppl√©mentaires
            use_form_data: Si True, utilise data au lieu de json pour l'envoi
            
        Returns:
            Donn√©es de la r√©ponse
            
        Raises:
            APIError: En cas d'erreur de l'API
            ConnectionError: En cas d'erreur de connexion
            AuthenticationError: En cas d'erreur d'authentification
        """
        url = urljoin(self.base_url, endpoint)
        
        # Headers personnalis√©s
        request_headers = headers or {}
        
        # Tentatives avec retry
        for attempt in range(self.retry_attempts):
            try:
                self.logger.debug(f"Requ√™te {method} vers {url} (tentative {attempt + 1})")
                
                # Pr√©parer les param√®tres de la requ√™te
                request_kwargs = {
                    'method': method,
                    'url': url,
                    'params': params,
                    'files': files,
                    'headers': request_headers,
                    'timeout': self.timeout
                }
                
                # Choisir entre json et data selon le param√®tre use_form_data
                if data is not None:
                    if use_form_data:
                        request_kwargs['data'] = data
                        # Retirer le Content-Type de la session pour permettre √† requests de le d√©finir automatiquement
                        if 'Content-Type' in self.session.headers:
                            del self.session.headers['Content-Type']
                    else:
                        request_kwargs['json'] = data
                
                response = self.session.request(**request_kwargs)
                
                # Gestion des codes de statut
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 204:
                    return {}
                else:
                    # Cr√©er l'exception appropri√©e
                    try:
                        error_data = response.json()
                    except json.JSONDecodeError:
                        error_data = {"detail": response.text}
                    
                    exception = create_exception_from_response(
                        response.status_code, error_data
                    )
                    raise exception
                    
            except requests.exceptions.RequestException as e:
                if attempt == self.retry_attempts - 1:
                    raise ConnectionError(
                        f"Erreur de connexion apr√®s {self.retry_attempts} tentatives: {e}",
                        url=url,
                        timeout=self.timeout
                    )
                
                self.logger.warning(f"Tentative {attempt + 1} √©chou√©e: {e}")
                import time
                time.sleep(self.retry_delay)
        
        raise ConnectionError("Toutes les tentatives ont √©chou√©")
    
    # ==================== AUTHENTIFICATION ====================
    
    def authenticate(self, email: str, password: str) -> Dict[str, Any]:
        """
        Authentifie l'utilisateur et r√©cup√®re un token JWT.
        
        Args:
            email: Adresse email
            password: Mot de passe
            
        Returns:
            Informations d'authentification
            
        Raises:
            AuthenticationError: En cas d'√©chec d'authentification
        """
        return self.auth.authenticate(email, password)
    
    def logout(self) -> bool:
        """
        D√©connecte l'utilisateur.
        
        Returns:
            True si la d√©connexion a r√©ussi
        """
        return self.auth.logout()
    
    def get_profile(self) -> User:
        """
        R√©cup√®re le profil de l'utilisateur connect√©.
        
        Returns:
            Informations du profil utilisateur
        """
        return self.auth.get_profile()
    
    def update_profile(self, **kwargs) -> User:
        """
        Met √† jour le profil utilisateur.
        
        Args:
            **kwargs: Champs √† mettre √† jour
            
        Returns:
            Profil utilisateur mis √† jour
        """
        return self.auth.update_profile(**kwargs)
    
    # ==================== DONN√âES DE DENGUE ====================
   
    def get_cas_dengue(self,
                       annee : int = date.today().year,
                       mois : int = date.today().month,
                       region : Optional[str] = None,
                       district : Optional[str] = None,
                       ) -> List[CasDengue]:
        """_summary_

        Args:
            annee (int, optional): _description_. Defaults to date.today().year.
            mois (int, optional): _description_. Defaults to date.today().month.
            region (Optional[str], optional): _description_. Defaults to None.
            district (Optional[str], optional): _description_. Defaults to None.

        Returns:
            List[CasDengue]: _description_
        """
        params = {
            'annee': annee,
            'mois': mois,
            'region': region,
            'district': district
        }
        
        data = self._make_request("GET", "/api/data/hebdomadaires", params=params)
        
        
        # Conversion en objets CasDengue
        cas_list = []
        for cas_data in data if isinstance(data, list) else data.get('data', []):
            try:
                cas = CasDengue(**cas_data)
                cas_list.append(cas)
            except Exception as e:
                self.logger.warning(f"Erreur de validation du cas: {e}")
        
        return cas_list
    
    # a revoir
    def add_cas_dengue(self, cas_list: List[ValidationCasDengue]) -> Dict[str, Any]:
        """
        Ajoute une liste de cas de dengue.
        
        Args:
            cas_list: Liste des cas √† ajouter
            
        Returns:
            R√©sultat de l'ajout
        """
        try:
            data = [cas.model_dump() for cas in cas_list]
        except Exception as e:
            data = cas_list
            
        return self._make_request("POST", "/add-listCasDengue-json/", data=data)
    
    def get_stats(self) -> Statistiques:
        """
        R√©cup√®re les statistiques g√©n√©rales.
        
        Returns:
            Statistiques du syst√®me
        """
        data = self._make_request("GET", "/api/stats")
        
        # Transformer les donn√©es de l'API au format attendu par le mod√®le Statistiques
        # L'API retourne une structure imbriqu√©e, on extrait les donn√©es de l'ann√©e en cours
        annee_courante = data.get('annee_en_cours', {})
        
        # Cr√©er un dictionnaire au format attendu par le mod√®le Statistiques
        stats_data = {
            'total_cas': annee_courante.get('total_cases', 0),
            'total_positifs': annee_courante.get('total_positives', 0),
            'total_hospitalisations': annee_courante.get('total_hospitalized', 0),
            'total_deces': annee_courante.get('total_deaths', 0),
            'regions_actives': [annee_courante.get('top_region', '')] if annee_courante.get('top_region') else [],
            'districts_actifs': [annee_courante.get('top_district', '')] if annee_courante.get('top_district') else [],
            'derniere_mise_a_jour': datetime.now()  # L'API ne fournit pas cette info, on utilise maintenant
        }
        
        return Statistiques(**stats_data)
    
    def get_regions(self) -> List[str]:
        """
        R√©cup√®re la liste des r√©gions.
        
        Returns:
            Liste des r√©gions disponibles
        """
        data = self._make_request("GET", "/api/regions")
        return data if isinstance(data, list) else data.get('regions', [])
    
    def get_districts(self, region: Optional[str] = None) -> List[str]:
        """
        R√©cup√®re la liste des districts.
        
        Args:
            region: R√©gion pour filtrer les districts
            
        Returns:
            Liste des districts
        """
        params = {}
        if region:
            params['region'] = region
        
        data = self._make_request("GET", "/api/districts", params=params)
        return data if isinstance(data, list) else data.get('districts', [])
    
    # ==================== INDICATEURS √âPID√âMIOLOGIQUES ====================
    # a revoir
    def donnees_par_periode(self,
        date_debut: Optional[str] = None,
        date_fin: Optional[str] = None,
        region: Optional[str] = None,
        district: Optional[str] = None,
        frequence: str = "W"
        ) -> List[IndicateurHebdo]:

        """
        R√©cup√®re les indicateurs hebdomadaires.
        
        Args:
            date_debut: Date de d√©but
            date_fin: Date de fin
            region: R√©gion
            district: District
            frequence: Fr√©quence (W: hebdomadaire, M: mensuel)
            
        Returns:
            Liste des indicateurs hebdomadaires
        """
        params = {
            'date_debut': date_debut,
            'date_fin': date_fin,
            'region': region,
            'district': district,
            'frequence': frequence
        }
        
        data = self._make_request("GET", "/api/time-series", params=params)
        
        indicateurs = []
        for ind_data in data:
            try:
                #indicateur = IndicateurHebdo(**ind_data)
                indicateurs.append(ind_data)
            except Exception as e:
                self.logger.warning(f"Erreur de validation de l'indicateur: {e}")
        
        return indicateurs
    
    def get_taux_hospitalisation(self,
                                date_debut: str,
                                date_fin: str,
                                region: str = "Toutes",
                                district: str = "Toutes") -> Dict[str, Any]:
        """
        R√©cup√®re le taux d'hospitalisation.
        
        Args:
            date_debut: Date de d√©but
            date_fin: Date de fin
            region: R√©gion
            district: District
            
        Returns:
            Donn√©es du taux d'hospitalisation
        """
        params = {
            'date_debut': date_debut,
            'date_fin': date_fin
        }
        
        if region != "Toutes":
            params['region'] = region
        if district != "Toutes":
            params['district'] = district
        
        return self._make_request("GET", "/indicateurs/taux-hospitalisation", params=params)
    
    def get_taux_letalite(self,
                          date_debut: str,
                          date_fin: str,
                          niveau: Optional[str] = None,
                          serotype: Optional[str] = None) -> Dict[str, Any]:
        """
        R√©cup√®re le taux de l√©talit√©.
        
        Args:
            date_debut: Date de d√©but
            date_fin: Date de fin
            niveau: Niveau d'agr√©gation (region, district)
            serotype: S√©rotype/variante √† filtrer 
            
        Returns:
            Donn√©es du taux de l√©talit√©
        """
        params = {
            'date_debut': date_debut,
            'date_fin': date_fin,
            'niveau': niveau if niveau else "region",
            'serotype': serotype if serotype else "Tous"
        }
        
        return self._make_request("GET", "/indicateurs/taux-deletalite", params=params)
    
    def get_taux_positivite(self,
                           date_debut: str,
                           date_fin: str,
                           region: Optional[str] = None,
                           district: Optional[str] = None) -> Dict[str, Any]:
        """
        R√©cup√®re le taux de positivit√©.
        
        Args:
            date_debut: Date de d√©but
            date_fin: Date de fin
            region: R√©gion
            district: District
            
        Returns:
            Donn√©es du taux de positivit√©
        """
        params = {
            'date_debut': date_debut,
            'date_fin': date_fin
        }
        
        if region:
            params['region'] = region
        if district:
            params['district'] = district
        
        return self._make_request("GET", "/indicateurs/taux-positivite", params=params)
    
    # ==================== SYST√àME D'ALERTES ====================
    
    def get_alertes(self,
                    limit: int = 10,
                    severity: Optional[str] = None,
                    status: Optional[str] = None,
                    region: Optional[str] = None,
                    district: Optional[str] = None,
                    date_debut: Optional[str] = None,
                    date_fin: Optional[str] = None) -> List[AlertLog]:
        """
        R√©cup√®re les alertes selon les crit√®res.
        
        Args:
            limit: Nombre maximum d'alertes
            severity: S√©v√©rit√© (warning, critical, info)
            status: Statut (active, resolved)
            region: R√©gion
            district: District
            date_debut: Date de d√©but
            date_fin: Date de fin
            
        Returns:
            Liste des alertes
        """
        return self.alerts.get_alertes(
            limit=limit,
            severity=severity,
            status=status,
            region=region,
            district=district,
            date_debut=date_debut,
            date_fin=date_fin
        )
    
    def configurer_seuils(self, **kwargs) -> Dict[str, Any]:
        """
        Configure les seuils d'alerte.
        
        Args:
            **kwargs: Param√®tres de configuration
            
        Returns:
            R√©sultat de la configuration
        """
        return self.alerts.configurer_seuils(**kwargs)
    
    def verifier_alertes(self,
                        date_debut: Optional[str] = None,
                        date_fin: Optional[str] = None,
                        region: str = "Toutes",
                        district: str = "Toutes") -> Dict[str, Any]:
        """
        V√©rifie les alertes selon les crit√®res.
        
        Args:
            date_debut: Date de d√©but
            date_fin: Date de fin
            region: R√©gion
            district: District
            
        Returns:
            R√©sultat de la v√©rification
        """
        return self.alerts.verifier_alertes(
            date_debut=date_debut,
            date_fin=date_fin,
            region=region,
            district=district
        )
    
    # ==================== EXPORT DE DONN√âES ====================
    
    def data(self,
            date_debut: Optional[str] = None,
            date_fin: Optional[str] = None,
            region: Optional[str] = None,
            district: Optional[str] = None,
            limit: Optional[int] = None,
            page: Optional[int] = None) -> pd.DataFrame:
        """
        R√©cup√®re les donn√©es de dengue sous forme de DataFrame.
        
        Args:
            date_debut: Date de d√©but (format YYYY-MM-DD)
            date_fin: Date de fin (format YYYY-MM-DD)
            region: R√©gion √† filtrer
            district: District √† filtrer
            limit: Nombre maximum de r√©sultats
            
        Returns:
            DataFrame avec les donn√©es de dengue
        """
        # R√©cup√©rer les cas de dengue
        params = {}
        if date_debut:
            params['date_debut'] = date_debut
        if date_fin:
            params['date_fin'] = date_fin
        if region:
            params['region'] = region
        if district:
            params['district'] = district
        if limit:
            params['limit'] = limit
        if page:
            params['page'] = page
        
        data = self._make_request("GET", "/api/data", params=params)
        
        cas_list = data if isinstance(data, list) else data.get('data', [])
        
        # Convertir en DataFrame
        if cas_list:
            # Cr√©er une liste de dictionnaires
            data_list = []
            for cas in cas_list:
                # cas_dict = cas.model_dump()
                # Convertir les dates en string pour pandas
                if cas.get('date_consultation'):
                    cas['date_consultation'] = str(cas['date_consultation'])
                data_list.append(cas)
            
            df = pd.DataFrame(data_list)
            
            # Convertir les colonnes de dates
            if 'date_consultation' in df.columns:
                df['date_consultation'] = pd.to_datetime(df['date_consultation'], errors='coerce')
            
            return df
        else:
            # Retourner un DataFrame vide avec les colonnes attendues
            return pd.DataFrame(columns=[
                'idCas', 'date_consultation', 'region', 'district', 'sexe', 'age',
                'resultat_test', 'serotype', 'hospitalise', 'issue', 'id_source'
            ])

    def save_to_file(self,
        filepath: Optional[str] = None,
        date_debut: Optional[str] = None,
        date_fin: Optional[str] = None,
        region: Optional[str] = None,
        district: Optional[str] = None,
        limit: Optional[int] = None,
        page: Optional[int] = None,
        format: str = "csv") -> bool:
            
        """
        Sauvegarde les donn√©es dans un fichier.
        
        Args:
            filepath: Chemin du fichier de sortie (optionnel, utilise le r√©pertoire courant si non fourni)
            date_debut: Date de d√©but (format YYYY-MM-DD)
            date_fin: Date de fin (format YYYY-MM-DD)
            region: R√©gion √† filtrer
            district: District √† filtrer
            limit: Nombre maximum de r√©sultats
            format: Format de sortie (csv, json, xlsx, parquet)
            
        Returns:
            True si la sauvegarde a r√©ussi
            
        Raises:
            ValueError: Si le format n'est pas support√©
            IOError: En cas d'erreur d'√©criture
        """
        # R√©cup√©rer les donn√©es
        df = self.data(
            date_debut=date_debut,
            date_fin=date_fin,
            region=region,
            district=district,
            limit=limit,
            page=page
        )
        
        # Si aucun filepath n'est fourni, utiliser le r√©pertoire courant
        if filepath is None:
            import os
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"dengue_data_{timestamp}"
            filepath = os.path.join(os.getcwd(), filename)
        
        # D√©terminer l'extension si non fournie
        if not filepath.endswith(('.csv', '.json', '.xlsx', '.parquet')):
            if format == "csv":
                filepath += ".csv"
            elif format == "json":
                filepath += ".json"
            elif format == "xlsx":
                filepath += ".xlsx"
            elif format == "parquet":
                filepath += ".parquet"
        
        # Sauvegarder selon le format
        try:
            if format == "csv":
                df.to_csv(filepath, index=False, encoding='utf-8')
            elif format == "json":
                df.to_json(filepath, orient='records', indent=2, date_format='iso')
            elif format == "xlsx":
                df.to_excel(filepath, index=False, engine='openpyxl')
            elif format == "parquet":
                df.to_parquet(filepath, index=False)
            else:
                raise ValueError(f"Format non support√©: {format}. Formats support√©s: csv, json, xlsx, parquet")
            
            self.logger.info(f"Donn√©es sauvegard√©es dans {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"Erreur lors de la sauvegarde: {e}")
            raise IOError(f"Impossible de sauvegarder le fichier {filepath}: {e}")

    def alertes(self,
                      
            limit: int = 100,
            severity: Optional[str] = None,
            status: Optional[str] = None) -> pd.DataFrame:
        """
        Exporte les alertes dans diff√©rents formats.
        
        Args:
            format: Format d'export (csv, json, xlsx)
            limit: Nombre maximum d'alertes
            severity: S√©v√©rit√©
            status: Statut
            
        Returns:
            Alertes export√©es en bytes
        """
        return self.exporter.alertes_to_dataframe(
            #format=format,
            limit=limit,
            severity=severity,
            status=status
        )
    
    def alertes_to_file(self,
                          filepath: Optional[str] = None,
                          limit: int = 100,
                          severity: Optional[str] = None,
                          status: Optional[str] = None,
                          format: str = "csv") -> bool:
            """
            Sauvegarde les alertes dans un fichier.
            
            Args:
                filepath: Chemin du fichier de sortie
                limit: Nombre maximum d'alertes
                severity: S√©v√©rit√©
                status: Statut
                format: Format de sortie (csv, json, xlsx)
                
            Returns:
                True si la sauvegarde a r√©ussi
            """
            # R√©cup√©rer les alertes
            alertes = self.get_alertes(
                limit=limit,
                severity=severity,
                status=status
            )
            
             # Si aucun filepath n'est fourni, utiliser le r√©pertoire courant
            if filepath is None:
                import os
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"alertes_data_{timestamp}"
                filepath = os.path.join(os.getcwd(), filename)
            
            # Convertir en DataFrame
            if alertes:
                data_list = []
                for alerte in alertes:
                    alerte_dict = alerte.model_dump()
                    # Convertir les dates
                    if alerte_dict.get('created_at'):
                        alerte_dict['created_at'] = str(alerte_dict['created_at'])
                    data_list.append(alerte_dict)
                
                df = pd.DataFrame(data_list)
            else:
                df = pd.DataFrame(columns=[
                    'id', 'id_seuil', 'usermail', 'severity', 'status', 'message',
                    'region', 'district', 'notification_type', 'recipient', 'created_at'
                ])
            
            # D√©terminer l'extension si non fournie
            if not filepath.endswith(('.csv', '.json', '.xlsx')):
                if format == "csv":
                    filepath += ".csv"
                elif format == "json":
                    filepath += ".json"
                elif format == "xlsx":
                    filepath += ".xlsx"
            
            # Sauvegarder selon le format
            try:
                if format == "csv":
                    df.to_csv(filepath, index=False, encoding='utf-8')
                elif format == "json":
                    df.to_json(filepath, orient='records', indent=2, date_format='iso')
                elif format == "xlsx":
                    df.to_excel(filepath, index=False, engine='openpyxl')
                else:
                    raise ValueError(f"Format non support√©: {format}. Formats support√©s: csv, json, xlsx")
                
                self.logger.info(f"Alertes sauvegard√©es dans {filepath}")
                return True
                
            except Exception as e:
                self.logger.error(f"Erreur lors de la sauvegarde des alertes: {e}")
                raise IOError(f"Impossible de sauvegarder le fichier {filepath}: {e}")        

    # ==================== OUTILS D'ANALYSE ====================
    
    
    def detect_anomalies(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        D√©tecte les anomalies dans les donn√©es.
        
        Args:
            data: DataFrame avec les donn√©es
            
        Returns:
            DataFrame avec les anomalies d√©tect√©es
        """
        return self.analyzer.detect_anomalies(data)
    
    def calculate_rates(self,
                       date_debut: str,
                       date_fin: str,
                       region: Optional[str] = None,
                       district: Optional[str] = None) -> Dict[str, float]:
        """
        Calcule les taux √©pid√©miologiques.
        
        Args:
            date_debut: Date de d√©but
            date_fin: Date de fin
            region: R√©gion
            district: District
            
        Returns:
            Dictionnaire avec les taux calcul√©s
        """
        return self.analyzer.calculate_rates(
            date_debut=date_debut,
            date_fin=date_fin,
            region=region,
            district=district
        )
    
    # ==================== M√âTHODES UTILITAIRES ====================
    
    def clear_cache(self) -> None:
        """Vide le cache des requ√™tes."""
        self._cache.clear()
    
    def get_cache_info(self) -> Dict[str, Any]:
        """
        R√©cup√®re les informations sur le cache.
        
        Returns:
            Informations sur le cache
        """
        return {
            'size': len(self._cache),
            'ttl': self._cache_ttl,
            'keys': list(self._cache.keys())
        }
    
    def set_cache_ttl(self, ttl: int) -> None:
        """
        D√©finit la dur√©e de vie du cache.
        
        Args:
            ttl: Dur√©e de vie en secondes
        """
        self._cache_ttl = ttl
    
    def __enter__(self):
        """Support du context manager."""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Nettoyage lors de la sortie du context manager."""
        self.session.close()

    # ==================== RESUME ====================
    def resume(self,limit: int = None,date_debut: Optional[str] = None,date_fin: Optional[str] = None) -> Dict[str, Any]:
        """
        G√©n√®re un r√©sum√© statistique complet et professionnel de la base de donn√©es.
        
        Cette fonction analyse la base de donn√©es de surveillance de la dengue et fournit
        un aper√ßu d√©taill√© incluant les informations g√©n√©rales, les statistiques descriptives
        pour chaque variable, et la qualit√© des donn√©es.
        
        Returns:
            Dict contenant le r√©sum√© complet de la base de donn√©es avec la structure suivante:
            {
                "success": bool,
                "message": str,
                "periode_couverture": dict,
                "derniere_mise_a_jour": str,
                "informations_generales": dict,
                "variables": dict,
                "qualite_donnees": dict
            }
            
        Raises:
            APIError: En cas d'erreur lors de la r√©cup√©ration des donn√©es
            ValueError: En cas d'erreur dans les calculs statistiques
        """
        try:
            # R√©cup√©rer toutes les donn√©es
            df = self.data(limit=limit,date_debut=date_debut,date_fin=date_fin)
            
            if df.empty:
                return {
                    "success": True,
                    "message": "Base de donn√©es vide - aucun enregistrement trouv√©",
                    "periode_couverture": {},
                    "derniere_mise_a_jour": None,
                    "informations_generales": {
                        "total_enregistrements": 0,
                        "regions_couvertes": 0,
                        "districts_couverts": 0
                    },
                    "variables": {},
                    "qualite_donnees": {
                        "variables_completes": [],
                        "variables_avec_manquants": [],
                        "taux_completude_global": 0.0
                    }
                }
            
            # 1. Informations g√©n√©rales
            periode_couverture = {
                "date_debut": df['date_consultation'].min().strftime("%Y-%m-%d") if not df['date_consultation'].isna().all() else None,
                "date_fin": df['date_consultation'].max().strftime("%Y-%m-%d") if not df['date_consultation'].isna().all() else None,
                "duree_jours": (df['date_consultation'].max() - df['date_consultation'].min()).days if not df['date_consultation'].isna().all() else 0
            }
            
            informations_generales = {
                "total_enregistrements": len(df),
                "regions_couvertes": df['region'].nunique() if 'region' in df.columns else 0,
                "districts_couverts": df['district'].nunique() if 'district' in df.columns else 0
            }
            
            # 2. Analyse des variables
            variables = {
                "numeriques": {},
                "qualitatives": {}
            }
            
            # Identifier les types de variables
            for col in df.columns:
                if col in ['age', 'idCas', 'id_source'] or df[col].dtype in ['int64', 'float64']:
                    # Variables num√©riques
                    col_data = pd.to_numeric(df[col], errors='coerce')
                    manquantes = col_data.isna().sum()
                    
                    variables["numeriques"][col] = {
                        "type": str(df[col].dtype),
                        "valeurs_manquantes": int(manquantes),
                        "pourcentage_manquantes": round((manquantes / len(df)) * 100, 2),
                        "min": float(col_data.min()) if not col_data.isna().all() else None,
                        "max": float(col_data.max()) if not col_data.isna().all() else None,
                        "moyenne": round(float(col_data.mean()), 2) if not col_data.isna().all() else None,
                        "ecart_type": round(float(col_data.std()), 2) if not col_data.isna().all() else None,
                        "quartiles": {
                            "Q1": float(col_data.quantile(0.25)) if not col_data.isna().all() else None,
                            "Q2": float(col_data.quantile(0.50)) if not col_data.isna().all() else None,
                            "Q3": float(col_data.quantile(0.75)) if not col_data.isna().all() else None
                        },
                        "valeurs_uniques": int(col_data.nunique())
                    }
                else:
                    # Variables qualitatives
                    col_data = df[col].astype(str)
                    manquantes = col_data.isna().sum() + (col_data == 'nan').sum() + (col_data == 'None').sum()
                    
                    # Calculer le mode
                    mode_value = col_data.mode().iloc[0] if not col_data.empty else None
                    
                    # Distribution des valeurs (top 5)
                    value_counts = col_data.value_counts().head(5)
                    distribution = {str(k): int(v) for k, v in value_counts.items()}
                    
                    variables["qualitatives"][col] = {
                        "type": str(df[col].dtype),
                        "valeurs_manquantes": int(manquantes),
                        "pourcentage_manquantes": round((manquantes / len(df)) * 100, 2),
                        "mode": str(mode_value) if mode_value else None,
                        "valeurs_uniques": int(col_data.nunique()),
                        "distribution": distribution
                    }
            
            # 3. Qualit√© des donn√©es
            variables_completes = []
            variables_avec_manquants = []
            
            for col in df.columns:
                manquantes = df[col].isna().sum()
                if manquantes == 0:
                    variables_completes.append(col)
                else:
                    variables_avec_manquants.append(col)
            
            taux_completude = round(((len(df) * len(df.columns)) - df.isna().sum().sum()) / (len(df) * len(df.columns)) * 100, 2)
            
            qualite_donnees = {
                "variables_completes": variables_completes,
                "variables_avec_manquants": variables_avec_manquants,
                "taux_completude_global": taux_completude
            }
            
            # 4. Derni√®re mise √† jour (utiliser la date la plus r√©cente)
            date_ = self._make_request("GET", "/api/derniere-mise-a-jour")

            derniere_mise_a_jour = date_["derniere_mise_a_jour"] if date_["statut"] == True else "Date non trouv√©e"
            return {
                "success": True,
                "message": f"R√©sum√© de la base de donn√©es g√©n√©r√© avec succ√®s - {len(df)} enregistrements analys√©s",
                "periode_couverture": periode_couverture,
                "derniere_mise_a_jour": derniere_mise_a_jour,
                "informations_generales": informations_generales,
                "variables": variables,
                "qualite_donnees": qualite_donnees
            }
            
        except Exception as e:
            self.logger.error(f"Erreur lors de la g√©n√©ration du r√©sum√©: {e}")
            return {
                "success": False,
                "message": f"Erreur lors de la g√©n√©ration du r√©sum√©: {str(e)}",
                "periode_couverture": {},
                "derniere_mise_a_jour": None,
                "informations_generales": {},
                "variables": {},
                "qualite_donnees": {}
            }
    
    def resume_display(self, limit: int = None, verbose: bool = True, show_details: bool = True, graph: bool = False,date_debut: Optional[str] = None,date_fin: Optional[str] = None) -> None:
        """
        Affiche un r√©sum√© statistique professionnel de la base de donn√©es dans la console.
        
        Cette m√©thode g√©n√®re un affichage format√© similaire aux m√©thodes info() et describe()
        de pandas, avec une pr√©sentation claire et structur√©e des informations.
        
        Parameters:
            verbose: bool, default True
                Afficher les d√©tails complets pour chaque variable
            show_details: bool, default True
                Afficher les statistiques d√©taill√©es (quartiles, distribution, etc.)
            graph: bool, default False
                Afficher des graphiques descriptifs (histogrammes, diagrammes en barres, etc.)
        """
        try:
            # R√©cup√©rer le r√©sum√©
            resume_data = self.resume(limit=limit,date_debut=date_debut,date_fin=date_fin)
            
            if not resume_data.get('success'):
                print(f"‚ùå Erreur: {resume_data.get('message')}")
                return
            
            # En-t√™te principal
            print("=" * 80)
            print("üìä R√âSUM√â STATISTIQUE - BASE DE DONN√âES SURVEILLANCE DENGUE")
            print("=" * 80)
            
            # Informations g√©n√©rales
            info_gen = resume_data.get('informations_generales', {})
            periode = resume_data.get('periode_couverture', {})
            
            print(f"\nüìà INFORMATIONS G√âN√âRALES")
            print(f"   Total enregistrements: {info_gen.get('total_enregistrements', 0):,}")
            print(f"   R√©gions couvertes: {info_gen.get('regions_couvertes', 0)}")
            print(f"   Districts couverts: {info_gen.get('districts_couverts', 0)}")
            
            if periode.get('date_debut') and periode.get('date_fin'):
                print(f"   P√©riode: {periode['date_debut']} ‚Üí {periode['date_fin']}")
                print(f"   Dur√©e: {periode.get('duree_jours', 0)} jours")
            
            # Qualit√© des donn√©es
            qualite = resume_data.get('qualite_donnees', {})
            print(f"\nüîç QUALIT√â DES DONN√âES")
            print(f"   Taux de compl√©tude global: {qualite.get('taux_completude_global', 0):.1f}%")
            print(f"   Variables compl√®tes: {len(qualite.get('variables_completes', []))}")
            print(f"   Variables avec manquants: {len(qualite.get('variables_avec_manquants', []))}")
            
            if verbose:
                # Variables compl√®tes
                variables_completes = qualite.get('variables_completes', [])
                if variables_completes:
                    print(f"\n‚úÖ VARIABLES COMPL√àTES ({len(variables_completes)})")
                    for var in variables_completes[:10]:  # Limiter √† 10 pour l'affichage
                        print(f"   ‚Ä¢ {var}")
                    if len(variables_completes) > 10:
                        print(f"   ... et {len(variables_completes) - 10} autres")
                
                # Variables avec manquants
                variables_manquants = qualite.get('variables_avec_manquants', [])
                if variables_manquants:
                    print(f"\n‚ö†Ô∏è  VARIABLES AVEC VALEURS MANQUANTES ({len(variables_manquants)})")
                    for var in variables_manquants[:10]:
                        print(f"   ‚Ä¢ {var}")
                    if len(variables_manquants) > 10:
                        print(f"   ... et {len(variables_manquants) - 10} autres")
            
            # Variables num√©riques
            variables = resume_data.get('variables', {})
            numeriques = variables.get('numeriques', {})
            
            if numeriques:
                print(f"\nüìä VARIABLES NUM√âRIQUES ({len(numeriques)})")
                print("-" * 60)
                
                if show_details:
                    # En-t√™te du tableau
                    print(f"{'Variable':<20} {'Type':<10} {'Min':<8} {'Max':<8} {'Moyenne':<10} {'Manquants':<12}")
                    print("-" * 60)
                    
                    for var, stats in numeriques.items():
                        manquants_pct = stats.get('pourcentage_manquantes', 0)
                        manquants_str = f"{stats.get('valeurs_manquantes', 0)} ({manquants_pct:.1f}%)"
                        
                        print(f"{var:<20} {stats.get('type', ''):<10} "
                              f"{stats.get('min', 'N/A'):<8} {stats.get('max', 'N/A'):<8} "
                              f"{stats.get('moyenne', 'N/A'):<10} {manquants_str:<12}")
                else:
                    # Affichage simplifi√©
                    for var, stats in numeriques.items():
                        print(f"   {var}: {stats.get('type', '')} "
                              f"[{stats.get('min', 'N/A')} - {stats.get('max', 'N/A')}] "
                              f"({stats.get('pourcentage_manquantes', 0):.1f}% manquants)")
            
            # Variables qualitatives
            qualitatives = variables.get('qualitatives', {})
            
            if qualitatives:
                print(f"\nüìã VARIABLES QUALITATIVES ({len(qualitatives)})")
                print("-" * 60)
                
                if show_details:
                    # En-t√™te du tableau
                    print(f"{'Variable':<20} {'Type':<10} {'Mode':<15} {'Uniques':<10} {'Manquants':<12}")
                    print("-" * 60)
                    
                    for var, stats in qualitatives.items():
                        manquants_pct = stats.get('pourcentage_manquantes', 0)
                        manquants_str = f"{stats.get('valeurs_manquantes', 0)} ({manquants_pct:.1f}%)"
                        mode = stats.get('mode', 'N/A')
                        if mode and len(mode) > 12:
                            mode = mode[:9] + "..."
                        
                        print(f"{var:<20} {stats.get('type', ''):<10} {mode:<15} "
                              f"{stats.get('valeurs_uniques', 0):<10} {manquants_str:<12}")
                else:
                    # Affichage simplifi√©
                    for var, stats in qualitatives.items():
                        print(f"   {var}: {stats.get('type', '')} "
                              f"Mode: {stats.get('mode', 'N/A')} "
                              f"({stats.get('valeurs_uniques', 0)} valeurs uniques, "
                              f"{stats.get('pourcentage_manquantes', 0):.1f}% manquants)")
            
            # Derni√®re mise √† jour
            derniere_maj = resume_data.get('derniere_mise_a_jour')
            if derniere_maj:
                print(f"\nüïí DERNI√àRE MISE √Ä JOUR: {derniere_maj}")
            
            print("\n" + "=" * 80)
            
            # Affichage des graphiques si demand√©
            if graph:
                self._display_graphs(resume_data)
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'affichage du r√©sum√©: {str(e)}")
            self.logger.error(f"Erreur lors de l'affichage du r√©sum√©: {e}")
    
    def _display_graphs(self, resume_data: Dict[str, Any], limit: int = None,date_debut: Optional[str] = None,date_fin: Optional[str] = None) -> None:
        """
        Affiche des graphiques descriptifs pour les variables de la base de donn√©es.
        
        Parameters:
            resume_data: Donn√©es du r√©sum√© statistique
        """
        try:
            # Importer les biblioth√®ques n√©cessaires
            import matplotlib.pyplot as plt
            import seaborn as sns
            import pandas as pd
            import numpy as np
            
            # Configuration du style
            plt.style.use('default')
            sns.set_palette("husl")
            
            # R√©cup√©rer les donn√©es
            df = self.data(limit=limit,date_debut=date_debut,date_fin=date_fin)
            if df.empty:
                print("‚ö†Ô∏è  Aucune donn√©e disponible pour les graphiques")
                return
            
            variables = resume_data.get('variables', {})
            numeriques = variables.get('numeriques', {})
            qualitatives = variables.get('qualitatives', {})
            
            # Calculer le nombre de graphiques √† afficher
            total_graphs = len(numeriques) + min(len(qualitatives), 5)  # Limiter les qualitatives
            if total_graphs == 0:
                print("‚ö†Ô∏è  Aucune variable disponible pour les graphiques")
                return
            
            # Configuration de la grille de graphiques
            cols = 3
            rows = (total_graphs + cols - 1) // cols
            
            print(f"\nüìä GRAPHIQUES DESCRIPTIFS ({total_graphs} variables)")
            print("=" * 80)
            
            # Cr√©er la figure principale
            fig = plt.figure(figsize=(15, 4 * rows))
            fig.suptitle('Analyse Descriptive - Base de Donn√©es Surveillance Dengue', 
                        fontsize=16, fontweight='bold', y=0.98)
            
            plot_idx = 1
            
            # Graphiques pour les variables num√©riques
            for var, stats in numeriques.items():
                if var in ['idCas', 'id_source']:
                    continue  # Ne pas afficher les identifiants
                if plot_idx > total_graphs:
                    break
                    
                plt.subplot(rows, cols, plot_idx)
                
                # Filtrer les valeurs non-nulles
                data_clean = pd.to_numeric(df[var], errors='coerce').dropna()
                
                if len(data_clean) > 0:
                    # Histogramme avec courbe de densit√©
                    plt.hist(data_clean, bins=min(20, len(data_clean)//5), 
                            alpha=0.7, density=True, color='skyblue', edgecolor='black')
                    
                    # Courbe de densit√© uniquement si plus d'une valeur unique
                    if len(data_clean) > 10 and data_clean.nunique() > 1:
                        from scipy import stats
                        kde_x = np.linspace(data_clean.min(), data_clean.max(), 100)
                        try:
                            kde = stats.gaussian_kde(data_clean)
                            plt.plot(kde_x, kde(kde_x), 'r-', linewidth=2, label='Densit√©')
                        except Exception as kde_err:
                            print(f"‚ö†Ô∏è  Densit√© non trac√©e pour {var}: {kde_err}")
                    else:
                        print(f"‚ö†Ô∏è  Densit√© non trac√©e pour {var}: donn√©es constantes ou insuffisantes.")
                    
                    plt.title(f'Distribution de {var}', fontweight='bold')
                    plt.xlabel(var)
                    plt.ylabel('Densit√©')
                    plt.legend()
                    plt.grid(True, alpha=0.3)
                    
                    # Ajouter des statistiques en texte
                    mean_val = data_clean.mean()
                    std_val = data_clean.std()
                    plt.text(0.02, 0.98, f'Moyenne: {mean_val:.2f}\n√âcart-type: {std_val:.2f}', 
                            transform=plt.gca().transAxes, verticalalignment='top',
                            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                
                plot_idx += 1
            
            # Graphiques pour les variables qualitatives (top 5)
            qual_vars = [(k, v) for k, v in list(qualitatives.items())[:5] if k not in ['idCas', 'id_source']]
            for var, stats in qual_vars:
                if plot_idx > total_graphs:
                    break
                    
                plt.subplot(rows, cols, plot_idx)
                
                # Compter les valeurs
                value_counts = df[var].value_counts().head(10)  # Top 10
                
                if len(value_counts) > 0:
                    # Diagramme en barres
                    bars = plt.bar(range(len(value_counts)), value_counts.values, 
                                 color=plt.cm.Set3(np.linspace(0, 1, len(value_counts))))
                    
                    plt.title(f'Distribution de {var}', fontweight='bold')
                    plt.xlabel(var)
                    plt.ylabel('Fr√©quence')
                    
                    # Rotation des labels si n√©cessaire
                    plt.xticks(range(len(value_counts)), value_counts.index, 
                              rotation=45, ha='right')
                    
                    # Ajouter les valeurs sur les barres
                    for i, (bar, count) in enumerate(zip(bars, value_counts.values)):
                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01*max(value_counts.values),
                                f'{count}', ha='center', va='bottom', fontweight='bold')
                    
                    plt.grid(True, alpha=0.3, axis='y')
                
                plot_idx += 1
            
            # Ajuster la mise en page
            plt.tight_layout()
            plt.subplots_adjust(top=0.92)
            
            # Afficher le graphique
            plt.show()
            
            # Graphiques suppl√©mentaires pour les variables importantes
            self._display_special_graphs(df, resume_data)
            
        except ImportError as e:
            print(f"‚ö†Ô∏è  Biblioth√®ques de graphiques non disponibles: {e}")
            print("   Installez matplotlib et seaborn: pip install matplotlib seaborn scipy")
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration des graphiques: {str(e)}")
            self.logger.error(f"Erreur lors de la g√©n√©ration des graphiques: {e}")
    
    def _display_special_graphs(self, df: pd.DataFrame, resume_data: Dict[str, Any]) -> None:
        """
        Affiche des graphiques sp√©ciaux pour des analyses plus avanc√©es.
        
        Parameters:
            df: DataFrame avec les donn√©es
            resume_data: Donn√©es du r√©sum√© statistique
        """
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns
            import pandas as pd
            import numpy as np
            
            # V√©rifier si nous avons des variables temporelles
            if 'date_consultation' in df.columns:
                print("\nüìà ANALYSE TEMPORELLE")
                print("-" * 40)
                
                # Convertir en datetime si n√©cessaire
                df['date_consultation'] = pd.to_datetime(df['date_consultation'], errors='coerce')
                df_temp = df.dropna(subset=['date_consultation'])
                
                if len(df_temp) > 0:
                    # √âvolution temporelle des cas
                    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
                    
                    # Graphique 1: √âvolution mensuelle
                    monthly_cases = df_temp.groupby(df_temp['date_consultation'].dt.to_period('M')).size()
                    monthly_cases.plot(kind='line', marker='o', ax=ax1, color='red', linewidth=2)
                    ax1.set_title('√âvolution Mensuelle des Cas de Dengue', fontweight='bold')
                    ax1.set_xlabel('Mois')
                    ax1.set_ylabel('Nombre de cas')
                    ax1.grid(True, alpha=0.3)
                    
                    # Graphique 2: R√©partition par r√©gion (si disponible)
                    if 'region' in df.columns:
                        region_counts = df_temp['region'].value_counts().head(8)
                        region_counts.plot(kind='bar', ax=ax2, color='lightcoral')
                        ax2.set_title('R√©partition par R√©gion', fontweight='bold')
                        ax2.set_xlabel('R√©gion')
                        ax2.set_ylabel('Nombre de cas')
                        ax2.tick_params(axis='x', rotation=45)
                        ax2.grid(True, alpha=0.3, axis='y')
                    
                    plt.tight_layout()
                    plt.show()
            
            # Analyse des variables num√©riques importantes
            if 'age' in df.columns:
                print("\nüë• ANALYSE D√âMOGRAPHIQUE")
                print("-" * 40)
                
                age_data = pd.to_numeric(df['age'], errors='coerce').dropna()
                if len(age_data) > 0:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
                    
                    # Distribution des √¢ges
                    ax1.hist(age_data, bins=20, alpha=0.7, color='lightblue', edgecolor='black')
                    ax1.set_title('Distribution des √Çges', fontweight='bold')
                    ax1.set_xlabel('√Çge')
                    ax1.set_ylabel('Fr√©quence')
                    ax1.grid(True, alpha=0.3)
                    
                    # Box plot des √¢ges
                    ax2.boxplot(age_data, patch_artist=True, 
                              boxprops=dict(facecolor='lightgreen', alpha=0.7))
                    ax2.set_title('Box Plot des √Çges', fontweight='bold')
                    ax2.set_ylabel('√Çge')
                    ax2.grid(True, alpha=0.3)
                    
                    plt.tight_layout()
                    plt.show()
            
            # Analyse des issues (si disponible)
            if 'issue' in df.columns:
                print("\nüè• ANALYSE DES ISSUES")
                print("-" * 40)
                
                issue_counts = df['issue'].value_counts()
                if len(issue_counts) > 0:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
                    
                    # Diagramme circulaire
                    colors = plt.cm.Pastel1(np.linspace(0, 1, len(issue_counts)))
                    wedges, texts, autotexts = ax1.pie(issue_counts.values, labels=issue_counts.index, 
                                                       autopct='%1.1f%%', colors=colors, startangle=90)
                    ax1.set_title('R√©partition des Issues', fontweight='bold')
                    
                    # Diagramme en barres
                    bars = ax2.bar(range(len(issue_counts)), issue_counts.values, 
                                 color=colors)
                    ax2.set_title('Nombre par Issue', fontweight='bold')
                    ax2.set_xlabel('Issue')
                    ax2.set_ylabel('Nombre de cas')
                    ax2.set_xticks(range(len(issue_counts)))
                    ax2.set_xticklabels(issue_counts.index, rotation=45, ha='right')
                    
                    # Ajouter les valeurs sur les barres
                    for i, (bar, count) in enumerate(zip(bars, issue_counts.values)):
                        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01*max(issue_counts.values),
                                f'{count}', ha='center', va='bottom', fontweight='bold')
                    
                    plt.tight_layout()
                    plt.show()
                    
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur lors de la g√©n√©ration des graphiques sp√©ciaux: {str(e)}")
            self.logger.error(f"Erreur lors de la g√©n√©ration des graphiques sp√©ciaux: {e}") 