"""
Client principal pour l'API Appi Dengue

Ce module contient la classe AppiClient qui fournit une interface
complÃ¨te pour interagir avec l'API de surveillance de la dengue.
"""

import os
import requests
import pandas as pd
from typing import List, Optional, Dict, Any, Union
from datetime import datetime, date, timedelta
import json
import logging
from urllib.parse import urljoin

from .models import (
    CasDengue, SoumissionDonnee, AlertLog, SeuilAlert, User,
    ValidationCasDengue, IndicateurHebdo, Statistiques,
    LoginRequest, RegisterRequest, AlertConfigRequest
)
from .exceptions import (
    AppiException, AuthenticationError, APIError, ValidationError,
    RateLimitError, ConnectionError, create_exception_from_response
)
from .auth import AuthManager
from .alerts import AlertManager
from .export import DataExporter
from .analytics import EpidemiologicalAnalyzer

os.environ['APPI_API_URL'] = "https://api-bf-dengue-survey-production.up.railway.app/"

class AppiClient:
    """
    Client principal pour l'API de surveillance de la dengue Appi.
    
    Cette classe fournit une interface complÃ¨te pour accÃ©der aux donnÃ©es
    Ã©pidÃ©miologiques, gÃ©rer les alertes et effectuer des analyses.
    """
    
    def __init__(self, 
                 
                 base_url: str = "https://api-bf-dengue-survey-production.up.railway.app/"
, 
                 api_key: Optional[str] = None,
                 timeout: int = 30,
                 retry_attempts: int = 3,
                 retry_delay: float = 1.0,
                 debug: bool = False):
        """
        Initialise le client Appi.
        
        Args:
            base_url: URL de base de l'API
            api_key: ClÃ© API optionnelle
            timeout: Timeout des requÃªtes en secondes
            retry_attempts: Nombre de tentatives en cas d'Ã©chec
            retry_delay: DÃ©lai entre les tentatives en secondes
            debug: Mode debug pour les logs dÃ©taillÃ©s
        """
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.timeout = timeout
        self.retry_attempts = retry_attempts
        self.retry_delay = retry_delay
        self.debug = debug
        
        # Configuration du logging
        if debug:
            logging.basicConfig(level=logging.DEBUG)
        self.logger = logging.getLogger(__name__)
        
        # Session HTTP avec configuration
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'dengsurvap-bf/0.1.0',
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        })
        
        if api_key:
            self.session.headers.update({'Authorization': f'Bearer {api_key}'})
        
        # Modules spÃ©cialisÃ©s
        self.auth = AuthManager(self)
        self.alerts = AlertManager(self)
        self.exporter = DataExporter(self)
        self.analyzer = EpidemiologicalAnalyzer(self)
        
        # Cache pour les requÃªtes frÃ©quentes
        self._cache = {}
        self._cache_ttl = 300  # 5 minutes
        
    @classmethod
    def from_env(cls) -> 'AppiClient':
        """
        CrÃ©e une instance du client Ã  partir des variables d'environnement.
        
        Returns:
            Instance du client configurÃ©e
            
        Raises:
            ConfigurationError: Si les variables requises sont manquantes
        """
        base_url = os.getenv('APPI_API_URL')
        api_key = os.getenv('APPI_API_KEY')
        debug = os.getenv('APPI_DEBUG', 'false').lower() == 'true'
        
        if not base_url:
            raise AppiException("Variable d'environnement APPI_API_URL requise")
        
        return cls(
            base_url=base_url,
            api_key=api_key,
            debug=debug
        )
    
    def _make_request(self, 
                     method: str, 
                     endpoint: str, 
                     params: Optional[Dict[str, Any]] = None,
                     data: Optional[Dict[str, Any]] = None,
                     files: Optional[Dict[str, Any]] = None,
                     headers: Optional[Dict[str, str]] = None,
                     use_form_data: bool = False) -> Dict[str, Any]:
        """
        Effectue une requÃªte HTTP vers l'API avec gestion d'erreurs et retry.
        
        Args:
            method: MÃ©thode HTTP (GET, POST, etc.)
            endpoint: Endpoint de l'API
            params: ParamÃ¨tres de requÃªte
            data: DonnÃ©es Ã  envoyer
            files: Fichiers Ã  envoyer
            headers: Headers HTTP supplÃ©mentaires
            use_form_data: Si True, utilise data au lieu de json pour l'envoi
            
        Returns:
            DonnÃ©es de la rÃ©ponse
            
        Raises:
            APIError: En cas d'erreur de l'API
            ConnectionError: En cas d'erreur de connexion
            AuthenticationError: En cas d'erreur d'authentification
        """
        url = urljoin(self.base_url, endpoint)
        
        # Headers personnalisÃ©s
        request_headers = headers or {}
        
        # Tentatives avec retry
        for attempt in range(self.retry_attempts):
            try:
                self.logger.debug(f"RequÃªte {method} vers {url} (tentative {attempt + 1})")
                
                # PrÃ©parer les paramÃ¨tres de la requÃªte
                request_kwargs = {
                    'method': method,
                    'url': url,
                    'params': params,
                    'files': files,
                    'headers': request_headers,
                    'timeout': self.timeout
                }
                
                # Choisir entre json et data selon le paramÃ¨tre use_form_data
                if data is not None:
                    if use_form_data:
                        request_kwargs['data'] = data
                        # Retirer le Content-Type de la session pour permettre Ã  requests de le dÃ©finir automatiquement
                        if 'Content-Type' in self.session.headers:
                            del self.session.headers['Content-Type']
                    else:
                        request_kwargs['json'] = data
                
                response = self.session.request(**request_kwargs)
                
                # Gestion des codes de statut
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 204:
                    return {}
                else:
                    # CrÃ©er l'exception appropriÃ©e
                    try:
                        error_data = response.json()
                    except json.JSONDecodeError:
                        error_data = {"detail": response.text}
                    
                    exception = create_exception_from_response(
                        response.status_code, error_data
                    )
                    raise exception
                    
            except requests.exceptions.RequestException as e:
                if attempt == self.retry_attempts - 1:
                    raise ConnectionError(
                        f"Erreur de connexion aprÃ¨s {self.retry_attempts} tentatives: {e}",
                        url=url,
                        timeout=self.timeout
                    )
                
                self.logger.warning(f"Tentative {attempt + 1} Ã©chouÃ©e: {e}")
                import time
                time.sleep(self.retry_delay)
        
        raise ConnectionError("Toutes les tentatives ont Ã©chouÃ©")
    
    # ==================== AUTHENTIFICATION ====================
    
    def authenticate(self, email: str, password: str) -> Dict[str, Any]:
        """
        Authentifie l'utilisateur et rÃ©cupÃ¨re un token JWT.
        
        Args:
            email: Adresse email
            password: Mot de passe
            
        Returns:
            Informations d'authentification
            
        Raises:
            AuthenticationError: En cas d'Ã©chec d'authentification
        """
        return self.auth.authenticate(email, password)
    
    def logout(self) -> bool:
        """
        DÃ©connecte l'utilisateur.
        
        Returns:
            True si la dÃ©connexion a rÃ©ussi
        """
        return self.auth.logout()
    
    def get_profile(self) -> User:
        """
        RÃ©cupÃ¨re le profil de l'utilisateur connectÃ©.
        
        Returns:
            Informations du profil utilisateur
        """
        return self.auth.get_profile()
    
    def update_profile(self, **kwargs) -> User:
        """
        Met Ã  jour le profil utilisateur.
        
        Args:
            **kwargs: Champs Ã  mettre Ã  jour
            
        Returns:
            Profil utilisateur mis Ã  jour
        """
        return self.auth.update_profile(**kwargs)
    
    # ==================== DONNÃ‰ES DE DENGUE ====================
    
    def get_cas_dengue(self,
                       date_debut: Optional[str] = None,
                       date_fin: Optional[str] = None,
                       region: Optional[str] = None,
                       district: Optional[str] = None,
                       limit: Optional[int] = None,
                       page: int = 1,
                       page_size: int = 100) -> List[CasDengue]:
        """
        RÃ©cupÃ¨re les cas de dengue selon les critÃ¨res.
        
        Args:
            date_debut: Date de dÃ©but (format YYYY-MM-DD)
            date_fin: Date de fin (format YYYY-MM-DD)
            region: RÃ©gion Ã  filtrer
            district: District Ã  filtrer
            limit: Nombre maximum de rÃ©sultats
            page: NumÃ©ro de page
            page_size: Taille de page
            
        Returns:
            Liste des cas de dengue
        """
        params = {
            'page': page,
            'page_size': page_size
        }
        
        if date_debut:
            params['date_debut'] = date_debut
        if date_fin:
            params['date_fin'] = date_fin
        if region:
            params['region'] = region
        if district:
            params['district'] = district
        if limit:
            params['limit'] = limit
        
        data = self._make_request("GET", "/api/data/hebdomadaires", params=params)
        
        # Conversion en objets CasDengue
        cas_list = []
        for cas_data in data if isinstance(data, list) else data.get('data', []):
            try:
                cas = CasDengue(**cas_data)
                cas_list.append(cas)
            except Exception as e:
                self.logger.warning(f"Erreur de validation du cas: {e}")
        
        return cas_list
    
    def add_cas_dengue(self, cas_list: List[ValidationCasDengue]) -> Dict[str, Any]:
        """
        Ajoute une liste de cas de dengue.
        
        Args:
            cas_list: Liste des cas Ã  ajouter
            
        Returns:
            RÃ©sultat de l'ajout
        """
        try:
            data = [cas.model_dump() for cas in cas_list]
        except Exception as e:
            data = cas_list
            
        return self._make_request("POST", "/add-listCasDengue-json/", data=data)
    
    def get_stats(self) -> Statistiques:
        """
        RÃ©cupÃ¨re les statistiques gÃ©nÃ©rales.
        
        Returns:
            Statistiques du systÃ¨me
        """
        data = self._make_request("GET", "/api/stats")
        
        # Transformer les donnÃ©es de l'API au format attendu par le modÃ¨le Statistiques
        # L'API retourne une structure imbriquÃ©e, on extrait les donnÃ©es de l'annÃ©e en cours
        annee_courante = data.get('annee_en_cours', {})
        
        # CrÃ©er un dictionnaire au format attendu par le modÃ¨le Statistiques
        stats_data = {
            'total_cas': annee_courante.get('total_cases', 0),
            'total_positifs': annee_courante.get('total_positives', 0),
            'total_hospitalisations': annee_courante.get('total_hospitalized', 0),
            'total_deces': annee_courante.get('total_deaths', 0),
            'regions_actives': [annee_courante.get('top_region', '')] if annee_courante.get('top_region') else [],
            'districts_actifs': [annee_courante.get('top_district', '')] if annee_courante.get('top_district') else [],
            'derniere_mise_a_jour': datetime.now()  # L'API ne fournit pas cette info, on utilise maintenant
        }
        
        return Statistiques(**stats_data)
    
    def get_regions(self) -> List[str]:
        """
        RÃ©cupÃ¨re la liste des rÃ©gions.
        
        Returns:
            Liste des rÃ©gions disponibles
        """
        data = self._make_request("GET", "/api/regions")
        return data if isinstance(data, list) else data.get('regions', [])
    
    def get_districts(self, region: Optional[str] = None) -> List[str]:
        """
        RÃ©cupÃ¨re la liste des districts.
        
        Args:
            region: RÃ©gion pour filtrer les districts
            
        Returns:
            Liste des districts
        """
        params = {}
        if region:
            params['region'] = region
        
        data = self._make_request("GET", "/api/districts", params=params)
        return data if isinstance(data, list) else data.get('districts', [])
    
    # ==================== INDICATEURS Ã‰PIDÃ‰MIOLOGIQUES ====================
    
    def data_period(self,
        date_debut: str,
        date_fin: str,
        region: str = "Toutes",
        district: str = "Tous",
        frequence: str = "W"
        ) -> List[IndicateurHebdo]:

        """
        RÃ©cupÃ¨re les indicateurs hebdomadaires.
        
        Args:
            date_debut: Date de dÃ©but
            date_fin: Date de fin
            region: RÃ©gion
            district: District
            frequence: FrÃ©quence (W: hebdomadaire, M: mensuel)
            
        Returns:
            Liste des indicateurs hebdomadaires
        """
        params = {
            'date_debut': date_debut,
            'date_fin': date_fin,
            'region': region,
            'district': district,
            'frequence': frequence
        }
        
        data = self._make_request("GET", "/api/time-series", params=params)
        
        indicateurs = []
        for ind_data in data['data']:
            try:
                indicateur = IndicateurHebdo(**ind_data)
                indicateurs.append(indicateur)
            except Exception as e:
                self.logger.warning(f"Erreur de validation de l'indicateur: {e}")
        
        return indicateurs
    
    def get_taux_hospitalisation(self,
                                date_debut: str,
                                date_fin: str,
                                region: str = "Toutes",
                                district: str = "Toutes") -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re le taux d'hospitalisation.
        
        Args:
            date_debut: Date de dÃ©but
            date_fin: Date de fin
            region: RÃ©gion
            district: District
            
        Returns:
            DonnÃ©es du taux d'hospitalisation
        """
        params = {
            'date_debut': date_debut,
            'date_fin': date_fin
        }
        
        if region != "Toutes":
            params['region'] = region
        if district != "Toutes":
            params['district'] = district
        
        return self._make_request("GET", "/indicateurs/taux-hospitalisation", params=params)
    
    def get_taux_letalite(self,
                          date_debut: str,
                          date_fin: str,
                          niveau: Optional[str] = None,
                          serotype: Optional[str] = None) -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re le taux de lÃ©talitÃ©.
        
        Args:
            date_debut: Date de dÃ©but
            date_fin: Date de fin
            niveau: Niveau d'agrÃ©gation (region, district)
            serotype: SÃ©rotype/variante Ã  filtrer 
            
        Returns:
            DonnÃ©es du taux de lÃ©talitÃ©
        """
        params = {
            'date_debut': date_debut,
            'date_fin': date_fin,
            'niveau': niveau if niveau else "region",
            'serotype': serotype if serotype else "Tous"
        }
        
        return self._make_request("GET", "/indicateurs/taux-deletalite", params=params)
    
    def get_taux_positivite(self,
                           date_debut: str,
                           date_fin: str,
                           region: Optional[str] = None,
                           district: Optional[str] = None) -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re le taux de positivitÃ©.
        
        Args:
            date_debut: Date de dÃ©but
            date_fin: Date de fin
            region: RÃ©gion
            district: District
            
        Returns:
            DonnÃ©es du taux de positivitÃ©
        """
        params = {
            'date_debut': date_debut,
            'date_fin': date_fin
        }
        
        if region:
            params['region'] = region
        if district:
            params['district'] = district
        
        return self._make_request("GET", "/indicateurs/taux-positivite", params=params)
    
    # ==================== SYSTÃˆME D'ALERTES ====================
    
    def get_alertes(self,
                    limit: int = 10,
                    severity: Optional[str] = None,
                    status: Optional[str] = None,
                    region: Optional[str] = None,
                    district: Optional[str] = None,
                    date_debut: Optional[str] = None,
                    date_fin: Optional[str] = None) -> List[AlertLog]:
        """
        RÃ©cupÃ¨re les alertes selon les critÃ¨res.
        
        Args:
            limit: Nombre maximum d'alertes
            severity: SÃ©vÃ©ritÃ© (warning, critical, info)
            status: Statut (active, resolved)
            region: RÃ©gion
            district: District
            date_debut: Date de dÃ©but
            date_fin: Date de fin
            
        Returns:
            Liste des alertes
        """
        return self.alerts.get_alertes(
            limit=limit,
            severity=severity,
            status=status,
            region=region,
            district=district,
            date_debut=date_debut,
            date_fin=date_fin
        )
    
    def configurer_seuils(self, **kwargs) -> Dict[str, Any]:
        """
        Configure les seuils d'alerte.
        
        Args:
            **kwargs: ParamÃ¨tres de configuration
            
        Returns:
            RÃ©sultat de la configuration
        """
        return self.alerts.configurer_seuils(**kwargs)
    
    def verifier_alertes(self,
                        date_debut: Optional[str] = None,
                        date_fin: Optional[str] = None,
                        region: str = "Toutes",
                        district: str = "Toutes") -> Dict[str, Any]:
        """
        VÃ©rifie les alertes selon les critÃ¨res.
        
        Args:
            date_debut: Date de dÃ©but
            date_fin: Date de fin
            region: RÃ©gion
            district: District
            
        Returns:
            RÃ©sultat de la vÃ©rification
        """
        return self.alerts.verifier_alertes(
            date_debut=date_debut,
            date_fin=date_fin,
            region=region,
            district=district
        )
    
    # ==================== EXPORT DE DONNÃ‰ES ====================
    
    def data(self,
            date_debut: Optional[str] = None,
            date_fin: Optional[str] = None,
            region: Optional[str] = None,
            district: Optional[str] = None,
            limit: Optional[int] = None,
            page: Optional[int] = None) -> pd.DataFrame:
        """
        RÃ©cupÃ¨re les donnÃ©es de dengue sous forme de DataFrame.
        
        Args:
            date_debut: Date de dÃ©but (format YYYY-MM-DD)
            date_fin: Date de fin (format YYYY-MM-DD)
            region: RÃ©gion Ã  filtrer
            district: District Ã  filtrer
            limit: Nombre maximum de rÃ©sultats
            
        Returns:
            DataFrame avec les donnÃ©es de dengue
        """
        # RÃ©cupÃ©rer les cas de dengue
        params = {}
        if date_debut:
            params['date_debut'] = date_debut
        if date_fin:
            params['date_fin'] = date_fin
        if region:
            params['region'] = region
        if district:
            params['district'] = district
        if limit:
            params['limit'] = limit
        if page:
            params['page'] = page
        
        data = self._make_request("GET", "/api/data", params=params)
        
        cas_list = data if isinstance(data, list) else data.get('data', [])
        
        # Convertir en DataFrame
        if cas_list:
            # CrÃ©er une liste de dictionnaires
            data_list = []
            for cas in cas_list:
                cas_dict = cas.model_dump()
                # Convertir les dates en string pour pandas
                if cas_dict.get('date_consultation'):
                    cas_dict['date_consultation'] = str(cas_dict['date_consultation'])
                data_list.append(cas_dict)
            
            df = pd.DataFrame(data_list)
            
            # Convertir les colonnes de dates
            if 'date_consultation' in df.columns:
                df['date_consultation'] = pd.to_datetime(df['date_consultation'], errors='coerce')
            
            return df
        else:
            # Retourner un DataFrame vide avec les colonnes attendues
            return pd.DataFrame(columns=[
                'idCas', 'date_consultation', 'region', 'district', 'sexe', 'age',
                'resultat_test', 'serotype', 'hospitalise', 'issue', 'id_source'
            ])

    def save_to_file(self,
        filepath: Optional[str] = None,
        date_debut: Optional[str] = None,
        date_fin: Optional[str] = None,
        region: Optional[str] = None,
        district: Optional[str] = None,
        limit: Optional[int] = None,
        page: Optional[int] = None,
        format: str = "csv") -> bool:
            
        """
        Sauvegarde les donnÃ©es dans un fichier.
        
        Args:
            filepath: Chemin du fichier de sortie (optionnel, utilise le rÃ©pertoire courant si non fourni)
            date_debut: Date de dÃ©but (format YYYY-MM-DD)
            date_fin: Date de fin (format YYYY-MM-DD)
            region: RÃ©gion Ã  filtrer
            district: District Ã  filtrer
            limit: Nombre maximum de rÃ©sultats
            format: Format de sortie (csv, json, xlsx, parquet)
            
        Returns:
            True si la sauvegarde a rÃ©ussi
            
        Raises:
            ValueError: Si le format n'est pas supportÃ©
            IOError: En cas d'erreur d'Ã©criture
        """
        # RÃ©cupÃ©rer les donnÃ©es
        df = self.data(
            date_debut=date_debut,
            date_fin=date_fin,
            region=region,
            district=district,
            limit=limit,
            page=page
        )
        
        # Si aucun filepath n'est fourni, utiliser le rÃ©pertoire courant
        if filepath is None:
            import os
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"dengue_data_{timestamp}"
            filepath = os.path.join(os.getcwd(), filename)
        
        # DÃ©terminer l'extension si non fournie
        if not filepath.endswith(('.csv', '.json', '.xlsx', '.parquet')):
            if format == "csv":
                filepath += ".csv"
            elif format == "json":
                filepath += ".json"
            elif format == "xlsx":
                filepath += ".xlsx"
            elif format == "parquet":
                filepath += ".parquet"
        
        # Sauvegarder selon le format
        try:
            if format == "csv":
                df.to_csv(filepath, index=False, encoding='utf-8')
            elif format == "json":
                df.to_json(filepath, orient='records', indent=2, date_format='iso')
            elif format == "xlsx":
                df.to_excel(filepath, index=False, engine='openpyxl')
            elif format == "parquet":
                df.to_parquet(filepath, index=False)
            else:
                raise ValueError(f"Format non supportÃ©: {format}. Formats supportÃ©s: csv, json, xlsx, parquet")
            
            self.logger.info(f"DonnÃ©es sauvegardÃ©es dans {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"Erreur lors de la sauvegarde: {e}")
            raise IOError(f"Impossible de sauvegarder le fichier {filepath}: {e}")

    def export_alertes(self,
                      format: str = "csv",
                      limit: int = 100,
                      severity: Optional[str] = None,
                      status: Optional[str] = None) -> bytes:
        """
        Exporte les alertes dans diffÃ©rents formats.
        
        Args:
            format: Format d'export (csv, json, xlsx)
            limit: Nombre maximum d'alertes
            severity: SÃ©vÃ©ritÃ©
            status: Statut
            
        Returns:
            Alertes exportÃ©es en bytes
        """
        return self.exporter.export_alertes(
            format=format,
            limit=limit,
            severity=severity,
            status=status
        )
    
    def export_alertes_to_file(self,
                          filepath: str,
                          limit: int = 100,
                          severity: Optional[str] = None,
                          status: Optional[str] = None,
                          format: str = "csv") -> bool:
            """
            Sauvegarde les alertes dans un fichier.
            
            Args:
                filepath: Chemin du fichier de sortie
                limit: Nombre maximum d'alertes
                severity: SÃ©vÃ©ritÃ©
                status: Statut
                format: Format de sortie (csv, json, xlsx)
                
            Returns:
                True si la sauvegarde a rÃ©ussi
            """
            # RÃ©cupÃ©rer les alertes
            alertes = self.get_alertes(
                limit=limit,
                severity=severity,
                status=status
            )
            
            # Convertir en DataFrame
            if alertes:
                data_list = []
                for alerte in alertes:
                    alerte_dict = alerte.model_dump()
                    # Convertir les dates
                    if alerte_dict.get('created_at'):
                        alerte_dict['created_at'] = str(alerte_dict['created_at'])
                    data_list.append(alerte_dict)
                
                df = pd.DataFrame(data_list)
            else:
                df = pd.DataFrame(columns=[
                    'id', 'id_seuil', 'usermail', 'severity', 'status', 'message',
                    'region', 'district', 'notification_type', 'recipient', 'created_at'
                ])
            
            # DÃ©terminer l'extension si non fournie
            if not filepath.endswith(('.csv', '.json', '.xlsx')):
                if format == "csv":
                    filepath += ".csv"
                elif format == "json":
                    filepath += ".json"
                elif format == "xlsx":
                    filepath += ".xlsx"
            
            # Sauvegarder selon le format
            try:
                if format == "csv":
                    df.to_csv(filepath, index=False, encoding='utf-8')
                elif format == "json":
                    df.to_json(filepath, orient='records', indent=2, date_format='iso')
                elif format == "xlsx":
                    df.to_excel(filepath, index=False, engine='openpyxl')
                else:
                    raise ValueError(f"Format non supportÃ©: {format}. Formats supportÃ©s: csv, json, xlsx")
                
                self.logger.info(f"Alertes sauvegardÃ©es dans {filepath}")
                return True
                
            except Exception as e:
                self.logger.error(f"Erreur lors de la sauvegarde des alertes: {e}")
                raise IOError(f"Impossible de sauvegarder le fichier {filepath}: {e}")        

    # ==================== OUTILS D'ANALYSE ====================
    
    def get_time_series(self,
                       date_debut: str,
                       date_fin: str,
                       frequency: str = "W",
                       region: str = "Toutes",
                       district: str = "Toutes") -> pd.DataFrame:
        """
        RÃ©cupÃ¨re une sÃ©rie temporelle des donnÃ©es.
        
        Args:
            date_debut: Date de dÃ©but
            date_fin: Date de fin
            frequency: FrÃ©quence (W: hebdomadaire, M: mensuel)
            region: RÃ©gion
            district: District
            
        Returns:
            DataFrame avec la sÃ©rie temporelle
        """
        return self.analyzer.get_time_series(
            date_debut=date_debut,
            date_fin=date_fin,
            frequency=frequency,
            region=region,
            district=district
        )
    
    def detect_anomalies(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        DÃ©tecte les anomalies dans les donnÃ©es.
        
        Args:
            data: DataFrame avec les donnÃ©es
            
        Returns:
            DataFrame avec les anomalies dÃ©tectÃ©es
        """
        return self.analyzer.detect_anomalies(data)
    
    def calculate_rates(self,
                       date_debut: str,
                       date_fin: str,
                       region: Optional[str] = None,
                       district: Optional[str] = None) -> Dict[str, float]:
        """
        Calcule les taux Ã©pidÃ©miologiques.
        
        Args:
            date_debut: Date de dÃ©but
            date_fin: Date de fin
            region: RÃ©gion
            district: District
            
        Returns:
            Dictionnaire avec les taux calculÃ©s
        """
        return self.analyzer.calculate_rates(
            date_debut=date_debut,
            date_fin=date_fin,
            region=region,
            district=district
        )
    
    # ==================== MÃ‰THODES UTILITAIRES ====================
    
    def clear_cache(self) -> None:
        """Vide le cache des requÃªtes."""
        self._cache.clear()
    
    def get_cache_info(self) -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re les informations sur le cache.
        
        Returns:
            Informations sur le cache
        """
        return {
            'size': len(self._cache),
            'ttl': self._cache_ttl,
            'keys': list(self._cache.keys())
        }
    
    def set_cache_ttl(self, ttl: int) -> None:
        """
        DÃ©finit la durÃ©e de vie du cache.
        
        Args:
            ttl: DurÃ©e de vie en secondes
        """
        self._cache_ttl = ttl
    
    def __enter__(self):
        """Support du context manager."""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Nettoyage lors de la sortie du context manager."""
        self.session.close()
    
    def resume(self) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re un rÃ©sumÃ© statistique complet et professionnel de la base de donnÃ©es.
        
        Cette fonction analyse la base de donnÃ©es de surveillance de la dengue et fournit
        un aperÃ§u dÃ©taillÃ© incluant les informations gÃ©nÃ©rales, les statistiques descriptives
        pour chaque variable, et la qualitÃ© des donnÃ©es.
        
        Returns:
            Dict contenant le rÃ©sumÃ© complet de la base de donnÃ©es avec la structure suivante:
            {
                "success": bool,
                "message": str,
                "periode_couverture": dict,
                "derniere_mise_a_jour": str,
                "informations_generales": dict,
                "variables": dict,
                "qualite_donnees": dict
            }
            
        Raises:
            APIError: En cas d'erreur lors de la rÃ©cupÃ©ration des donnÃ©es
            ValueError: En cas d'erreur dans les calculs statistiques
        """
        try:
            # RÃ©cupÃ©rer toutes les donnÃ©es
            df = self.data()
            
            if df.empty:
                return {
                    "success": True,
                    "message": "Base de donnÃ©es vide - aucun enregistrement trouvÃ©",
                    "periode_couverture": {},
                    "derniere_mise_a_jour": None,
                    "informations_generales": {
                        "total_enregistrements": 0,
                        "regions_couvertes": 0,
                        "districts_couverts": 0
                    },
                    "variables": {},
                    "qualite_donnees": {
                        "variables_completes": [],
                        "variables_avec_manquants": [],
                        "taux_completude_global": 0.0
                    }
                }
            
            # 1. Informations gÃ©nÃ©rales
            periode_couverture = {
                "date_debut": df['date_consultation'].min().strftime("%Y-%m-%d") if not df['date_consultation'].isna().all() else None,
                "date_fin": df['date_consultation'].max().strftime("%Y-%m-%d") if not df['date_consultation'].isna().all() else None,
                "duree_jours": (df['date_consultation'].max() - df['date_consultation'].min()).days if not df['date_consultation'].isna().all() else 0
            }
            
            informations_generales = {
                "total_enregistrements": len(df),
                "regions_couvertes": df['region'].nunique() if 'region' in df.columns else 0,
                "districts_couverts": df['district'].nunique() if 'district' in df.columns else 0
            }
            
            # 2. Analyse des variables
            variables = {
                "numeriques": {},
                "qualitatives": {}
            }
            
            # Identifier les types de variables
            for col in df.columns:
                if col in ['age', 'idCas', 'id_source'] or df[col].dtype in ['int64', 'float64']:
                    # Variables numÃ©riques
                    col_data = pd.to_numeric(df[col], errors='coerce')
                    manquantes = col_data.isna().sum()
                    
                    variables["numeriques"][col] = {
                        "type": str(df[col].dtype),
                        "valeurs_manquantes": int(manquantes),
                        "pourcentage_manquantes": round((manquantes / len(df)) * 100, 2),
                        "min": float(col_data.min()) if not col_data.isna().all() else None,
                        "max": float(col_data.max()) if not col_data.isna().all() else None,
                        "moyenne": round(float(col_data.mean()), 2) if not col_data.isna().all() else None,
                        "ecart_type": round(float(col_data.std()), 2) if not col_data.isna().all() else None,
                        "quartiles": {
                            "Q1": float(col_data.quantile(0.25)) if not col_data.isna().all() else None,
                            "Q2": float(col_data.quantile(0.50)) if not col_data.isna().all() else None,
                            "Q3": float(col_data.quantile(0.75)) if not col_data.isna().all() else None
                        },
                        "valeurs_uniques": int(col_data.nunique())
                    }
                else:
                    # Variables qualitatives
                    col_data = df[col].astype(str)
                    manquantes = col_data.isna().sum() + (col_data == 'nan').sum() + (col_data == 'None').sum()
                    
                    # Calculer le mode
                    mode_value = col_data.mode().iloc[0] if not col_data.empty else None
                    
                    # Distribution des valeurs (top 5)
                    value_counts = col_data.value_counts().head(5)
                    distribution = {str(k): int(v) for k, v in value_counts.items()}
                    
                    variables["qualitatives"][col] = {
                        "type": str(df[col].dtype),
                        "valeurs_manquantes": int(manquantes),
                        "pourcentage_manquantes": round((manquantes / len(df)) * 100, 2),
                        "mode": str(mode_value) if mode_value else None,
                        "valeurs_uniques": int(col_data.nunique()),
                        "distribution": distribution
                    }
            
            # 3. QualitÃ© des donnÃ©es
            variables_completes = []
            variables_avec_manquants = []
            
            for col in df.columns:
                manquantes = df[col].isna().sum()
                if manquantes == 0:
                    variables_completes.append(col)
                else:
                    variables_avec_manquants.append(col)
            
            taux_completude = round(((len(df) * len(df.columns)) - df.isna().sum().sum()) / (len(df) * len(df.columns)) * 100, 2)
            
            qualite_donnees = {
                "variables_completes": variables_completes,
                "variables_avec_manquants": variables_avec_manquants,
                "taux_completude_global": taux_completude
            }
            
            # 4. DerniÃ¨re mise Ã  jour (utiliser la date la plus rÃ©cente)
            derniere_mise_a_jour = df['date_consultation'].max().strftime("%Y-%m-%dT%H:%M:%S") if not df['date_consultation'].isna().all() else None
            
            return {
                "success": True,
                "message": f"RÃ©sumÃ© de la base de donnÃ©es gÃ©nÃ©rÃ© avec succÃ¨s - {len(df)} enregistrements analysÃ©s",
                "periode_couverture": periode_couverture,
                "derniere_mise_a_jour": derniere_mise_a_jour,
                "informations_generales": informations_generales,
                "variables": variables,
                "qualite_donnees": qualite_donnees
            }
            
        except Exception as e:
            self.logger.error(f"Erreur lors de la gÃ©nÃ©ration du rÃ©sumÃ©: {e}")
            return {
                "success": False,
                "message": f"Erreur lors de la gÃ©nÃ©ration du rÃ©sumÃ©: {str(e)}",
                "periode_couverture": {},
                "derniere_mise_a_jour": None,
                "informations_generales": {},
                "variables": {},
                "qualite_donnees": {}
            }
    
    def resume_display(self, verbose: bool = True, show_details: bool = True, graph: bool = False) -> None:
        """
        Affiche un rÃ©sumÃ© statistique professionnel de la base de donnÃ©es dans la console.
        
        Cette mÃ©thode gÃ©nÃ¨re un affichage formatÃ© similaire aux mÃ©thodes info() et describe()
        de pandas, avec une prÃ©sentation claire et structurÃ©e des informations.
        
        Parameters:
            verbose: bool, default True
                Afficher les dÃ©tails complets pour chaque variable
            show_details: bool, default True
                Afficher les statistiques dÃ©taillÃ©es (quartiles, distribution, etc.)
            graph: bool, default False
                Afficher des graphiques descriptifs (histogrammes, diagrammes en barres, etc.)
        """
        try:
            # RÃ©cupÃ©rer le rÃ©sumÃ©
            resume_data = self.resume()
            
            if not resume_data.get('success'):
                print(f"âŒ Erreur: {resume_data.get('message')}")
                return
            
            # En-tÃªte principal
            print("=" * 80)
            print("ðŸ“Š RÃ‰SUMÃ‰ STATISTIQUE - BASE DE DONNÃ‰ES SURVEILLANCE DENGUE")
            print("=" * 80)
            
            # Informations gÃ©nÃ©rales
            info_gen = resume_data.get('informations_generales', {})
            periode = resume_data.get('periode_couverture', {})
            
            print(f"\nðŸ“ˆ INFORMATIONS GÃ‰NÃ‰RALES")
            print(f"   Total enregistrements: {info_gen.get('total_enregistrements', 0):,}")
            print(f"   RÃ©gions couvertes: {info_gen.get('regions_couvertes', 0)}")
            print(f"   Districts couverts: {info_gen.get('districts_couverts', 0)}")
            
            if periode.get('date_debut') and periode.get('date_fin'):
                print(f"   PÃ©riode: {periode['date_debut']} â†’ {periode['date_fin']}")
                print(f"   DurÃ©e: {periode.get('duree_jours', 0)} jours")
            
            # QualitÃ© des donnÃ©es
            qualite = resume_data.get('qualite_donnees', {})
            print(f"\nðŸ” QUALITÃ‰ DES DONNÃ‰ES")
            print(f"   Taux de complÃ©tude global: {qualite.get('taux_completude_global', 0):.1f}%")
            print(f"   Variables complÃ¨tes: {len(qualite.get('variables_completes', []))}")
            print(f"   Variables avec manquants: {len(qualite.get('variables_avec_manquants', []))}")
            
            if verbose:
                # Variables complÃ¨tes
                variables_completes = qualite.get('variables_completes', [])
                if variables_completes:
                    print(f"\nâœ… VARIABLES COMPLÃˆTES ({len(variables_completes)})")
                    for var in variables_completes[:10]:  # Limiter Ã  10 pour l'affichage
                        print(f"   â€¢ {var}")
                    if len(variables_completes) > 10:
                        print(f"   ... et {len(variables_completes) - 10} autres")
                
                # Variables avec manquants
                variables_manquants = qualite.get('variables_avec_manquants', [])
                if variables_manquants:
                    print(f"\nâš ï¸  VARIABLES AVEC VALEURS MANQUANTES ({len(variables_manquants)})")
                    for var in variables_manquants[:10]:
                        print(f"   â€¢ {var}")
                    if len(variables_manquants) > 10:
                        print(f"   ... et {len(variables_manquants) - 10} autres")
            
            # Variables numÃ©riques
            variables = resume_data.get('variables', {})
            numeriques = variables.get('numeriques', {})
            
            if numeriques:
                print(f"\nðŸ“Š VARIABLES NUMÃ‰RIQUES ({len(numeriques)})")
                print("-" * 60)
                
                if show_details:
                    # En-tÃªte du tableau
                    print(f"{'Variable':<20} {'Type':<10} {'Min':<8} {'Max':<8} {'Moyenne':<10} {'Manquants':<12}")
                    print("-" * 60)
                    
                    for var, stats in numeriques.items():
                        manquants_pct = stats.get('pourcentage_manquantes', 0)
                        manquants_str = f"{stats.get('valeurs_manquantes', 0)} ({manquants_pct:.1f}%)"
                        
                        print(f"{var:<20} {stats.get('type', ''):<10} "
                              f"{stats.get('min', 'N/A'):<8} {stats.get('max', 'N/A'):<8} "
                              f"{stats.get('moyenne', 'N/A'):<10} {manquants_str:<12}")
                else:
                    # Affichage simplifiÃ©
                    for var, stats in numeriques.items():
                        print(f"   {var}: {stats.get('type', '')} "
                              f"[{stats.get('min', 'N/A')} - {stats.get('max', 'N/A')}] "
                              f"({stats.get('pourcentage_manquantes', 0):.1f}% manquants)")
            
            # Variables qualitatives
            qualitatives = variables.get('qualitatives', {})
            
            if qualitatives:
                print(f"\nðŸ“‹ VARIABLES QUALITATIVES ({len(qualitatives)})")
                print("-" * 60)
                
                if show_details:
                    # En-tÃªte du tableau
                    print(f"{'Variable':<20} {'Type':<10} {'Mode':<15} {'Uniques':<10} {'Manquants':<12}")
                    print("-" * 60)
                    
                    for var, stats in qualitatives.items():
                        manquants_pct = stats.get('pourcentage_manquantes', 0)
                        manquants_str = f"{stats.get('valeurs_manquantes', 0)} ({manquants_pct:.1f}%)"
                        mode = stats.get('mode', 'N/A')
                        if mode and len(mode) > 12:
                            mode = mode[:9] + "..."
                        
                        print(f"{var:<20} {stats.get('type', ''):<10} {mode:<15} "
                              f"{stats.get('valeurs_uniques', 0):<10} {manquants_str:<12}")
                else:
                    # Affichage simplifiÃ©
                    for var, stats in qualitatives.items():
                        print(f"   {var}: {stats.get('type', '')} "
                              f"Mode: {stats.get('mode', 'N/A')} "
                              f"({stats.get('valeurs_uniques', 0)} valeurs uniques, "
                              f"{stats.get('pourcentage_manquantes', 0):.1f}% manquants)")
            
            # DerniÃ¨re mise Ã  jour
            derniere_maj = resume_data.get('derniere_mise_a_jour')
            if derniere_maj:
                print(f"\nðŸ•’ DERNIÃˆRE MISE Ã€ JOUR: {derniere_maj}")
            
            print("\n" + "=" * 80)
            
            # Affichage des graphiques si demandÃ©
            if graph:
                self._display_graphs(resume_data)
            
        except Exception as e:
            print(f"âŒ Erreur lors de l'affichage du rÃ©sumÃ©: {str(e)}")
            self.logger.error(f"Erreur lors de l'affichage du rÃ©sumÃ©: {e}")
    
    def _display_graphs(self, resume_data: Dict[str, Any]) -> None:
        """
        Affiche des graphiques descriptifs pour les variables de la base de donnÃ©es.
        
        Parameters:
            resume_data: DonnÃ©es du rÃ©sumÃ© statistique
        """
        try:
            # Importer les bibliothÃ¨ques nÃ©cessaires
            import matplotlib.pyplot as plt
            import seaborn as sns
            import pandas as pd
            import numpy as np
            
            # Configuration du style
            plt.style.use('default')
            sns.set_palette("husl")
            
            # RÃ©cupÃ©rer les donnÃ©es
            df = self.data()
            if df.empty:
                print("âš ï¸  Aucune donnÃ©e disponible pour les graphiques")
                return
            
            variables = resume_data.get('variables', {})
            numeriques = variables.get('numeriques', {})
            qualitatives = variables.get('qualitatives', {})
            
            # Calculer le nombre de graphiques Ã  afficher
            total_graphs = len(numeriques) + min(len(qualitatives), 5)  # Limiter les qualitatives
            if total_graphs == 0:
                print("âš ï¸  Aucune variable disponible pour les graphiques")
                return
            
            # Configuration de la grille de graphiques
            cols = 3
            rows = (total_graphs + cols - 1) // cols
            
            print(f"\nðŸ“Š GRAPHIQUES DESCRIPTIFS ({total_graphs} variables)")
            print("=" * 80)
            
            # CrÃ©er la figure principale
            fig = plt.figure(figsize=(15, 4 * rows))
            fig.suptitle('Analyse Descriptive - Base de DonnÃ©es Surveillance Dengue', 
                        fontsize=16, fontweight='bold', y=0.98)
            
            plot_idx = 1
            
            # Graphiques pour les variables numÃ©riques
            for var, stats in numeriques.items():
                if plot_idx > total_graphs:
                    break
                    
                plt.subplot(rows, cols, plot_idx)
                
                # Filtrer les valeurs non-nulles
                data_clean = pd.to_numeric(df[var], errors='coerce').dropna()
                
                if len(data_clean) > 0:
                    # Histogramme avec courbe de densitÃ©
                    plt.hist(data_clean, bins=min(20, len(data_clean)//5), 
                            alpha=0.7, density=True, color='skyblue', edgecolor='black')
                    
                    # Courbe de densitÃ©
                    if len(data_clean) > 10:
                        from scipy import stats
                        kde_x = np.linspace(data_clean.min(), data_clean.max(), 100)
                        kde = stats.gaussian_kde(data_clean)
                        plt.plot(kde_x, kde(kde_x), 'r-', linewidth=2, label='DensitÃ©')
                    
                    plt.title(f'Distribution de {var}', fontweight='bold')
                    plt.xlabel(var)
                    plt.ylabel('DensitÃ©')
                    plt.legend()
                    plt.grid(True, alpha=0.3)
                    
                    # Ajouter des statistiques en texte
                    mean_val = data_clean.mean()
                    std_val = data_clean.std()
                    plt.text(0.02, 0.98, f'Moyenne: {mean_val:.2f}\nÃ‰cart-type: {std_val:.2f}', 
                            transform=plt.gca().transAxes, verticalalignment='top',
                            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                
                plot_idx += 1
            
            # Graphiques pour les variables qualitatives (top 5)
            qual_vars = list(qualitatives.items())[:5]
            for var, stats in qual_vars:
                if plot_idx > total_graphs:
                    break
                    
                plt.subplot(rows, cols, plot_idx)
                
                # Compter les valeurs
                value_counts = df[var].value_counts().head(10)  # Top 10
                
                if len(value_counts) > 0:
                    # Diagramme en barres
                    bars = plt.bar(range(len(value_counts)), value_counts.values, 
                                 color=plt.cm.Set3(np.linspace(0, 1, len(value_counts))))
                    
                    plt.title(f'Distribution de {var}', fontweight='bold')
                    plt.xlabel(var)
                    plt.ylabel('FrÃ©quence')
                    
                    # Rotation des labels si nÃ©cessaire
                    plt.xticks(range(len(value_counts)), value_counts.index, 
                              rotation=45, ha='right')
                    
                    # Ajouter les valeurs sur les barres
                    for i, (bar, count) in enumerate(zip(bars, value_counts.values)):
                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01*max(value_counts.values),
                                f'{count}', ha='center', va='bottom', fontweight='bold')
                    
                    plt.grid(True, alpha=0.3, axis='y')
                
                plot_idx += 1
            
            # Ajuster la mise en page
            plt.tight_layout()
            plt.subplots_adjust(top=0.92)
            
            # Afficher le graphique
            plt.show()
            
            # Graphiques supplÃ©mentaires pour les variables importantes
            self._display_special_graphs(df, resume_data)
            
        except ImportError as e:
            print(f"âš ï¸  BibliothÃ¨ques de graphiques non disponibles: {e}")
            print("   Installez matplotlib et seaborn: pip install matplotlib seaborn scipy")
        except Exception as e:
            print(f"âŒ Erreur lors de la gÃ©nÃ©ration des graphiques: {str(e)}")
            self.logger.error(f"Erreur lors de la gÃ©nÃ©ration des graphiques: {e}")
    
    def _display_special_graphs(self, df: pd.DataFrame, resume_data: Dict[str, Any]) -> None:
        """
        Affiche des graphiques spÃ©ciaux pour des analyses plus avancÃ©es.
        
        Parameters:
            df: DataFrame avec les donnÃ©es
            resume_data: DonnÃ©es du rÃ©sumÃ© statistique
        """
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns
            import pandas as pd
            import numpy as np
            
            # VÃ©rifier si nous avons des variables temporelles
            if 'date_consultation' in df.columns:
                print("\nðŸ“ˆ ANALYSE TEMPORELLE")
                print("-" * 40)
                
                # Convertir en datetime si nÃ©cessaire
                df['date_consultation'] = pd.to_datetime(df['date_consultation'], errors='coerce')
                df_temp = df.dropna(subset=['date_consultation'])
                
                if len(df_temp) > 0:
                    # Ã‰volution temporelle des cas
                    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
                    
                    # Graphique 1: Ã‰volution mensuelle
                    monthly_cases = df_temp.groupby(df_temp['date_consultation'].dt.to_period('M')).size()
                    monthly_cases.plot(kind='line', marker='o', ax=ax1, color='red', linewidth=2)
                    ax1.set_title('Ã‰volution Mensuelle des Cas de Dengue', fontweight='bold')
                    ax1.set_xlabel('Mois')
                    ax1.set_ylabel('Nombre de cas')
                    ax1.grid(True, alpha=0.3)
                    
                    # Graphique 2: RÃ©partition par rÃ©gion (si disponible)
                    if 'region' in df.columns:
                        region_counts = df_temp['region'].value_counts().head(8)
                        region_counts.plot(kind='bar', ax=ax2, color='lightcoral')
                        ax2.set_title('RÃ©partition par RÃ©gion', fontweight='bold')
                        ax2.set_xlabel('RÃ©gion')
                        ax2.set_ylabel('Nombre de cas')
                        ax2.tick_params(axis='x', rotation=45)
                        ax2.grid(True, alpha=0.3, axis='y')
                    
                    plt.tight_layout()
                    plt.show()
            
            # Analyse des variables numÃ©riques importantes
            if 'age' in df.columns:
                print("\nðŸ‘¥ ANALYSE DÃ‰MOGRAPHIQUE")
                print("-" * 40)
                
                age_data = pd.to_numeric(df['age'], errors='coerce').dropna()
                if len(age_data) > 0:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
                    
                    # Distribution des Ã¢ges
                    ax1.hist(age_data, bins=20, alpha=0.7, color='lightblue', edgecolor='black')
                    ax1.set_title('Distribution des Ã‚ges', fontweight='bold')
                    ax1.set_xlabel('Ã‚ge')
                    ax1.set_ylabel('FrÃ©quence')
                    ax1.grid(True, alpha=0.3)
                    
                    # Box plot des Ã¢ges
                    ax2.boxplot(age_data, patch_artist=True, 
                              boxprops=dict(facecolor='lightgreen', alpha=0.7))
                    ax2.set_title('Box Plot des Ã‚ges', fontweight='bold')
                    ax2.set_ylabel('Ã‚ge')
                    ax2.grid(True, alpha=0.3)
                    
                    plt.tight_layout()
                    plt.show()
            
            # Analyse des issues (si disponible)
            if 'issue' in df.columns:
                print("\nðŸ¥ ANALYSE DES ISSUES")
                print("-" * 40)
                
                issue_counts = df['issue'].value_counts()
                if len(issue_counts) > 0:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
                    
                    # Diagramme circulaire
                    colors = plt.cm.Pastel1(np.linspace(0, 1, len(issue_counts)))
                    wedges, texts, autotexts = ax1.pie(issue_counts.values, labels=issue_counts.index, 
                                                       autopct='%1.1f%%', colors=colors, startangle=90)
                    ax1.set_title('RÃ©partition des Issues', fontweight='bold')
                    
                    # Diagramme en barres
                    bars = ax2.bar(range(len(issue_counts)), issue_counts.values, 
                                 color=colors)
                    ax2.set_title('Nombre par Issue', fontweight='bold')
                    ax2.set_xlabel('Issue')
                    ax2.set_ylabel('Nombre de cas')
                    ax2.set_xticks(range(len(issue_counts)))
                    ax2.set_xticklabels(issue_counts.index, rotation=45, ha='right')
                    
                    # Ajouter les valeurs sur les barres
                    for i, (bar, count) in enumerate(zip(bars, issue_counts.values)):
                        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01*max(issue_counts.values),
                                f'{count}', ha='center', va='bottom', fontweight='bold')
                    
                    plt.tight_layout()
                    plt.show()
                    
        except Exception as e:
            print(f"âš ï¸  Erreur lors de la gÃ©nÃ©ration des graphiques spÃ©ciaux: {str(e)}")
            self.logger.error(f"Erreur lors de la gÃ©nÃ©ration des graphiques spÃ©ciaux: {e}") 